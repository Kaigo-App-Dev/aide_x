#!/usr/bin/env python3
"""
å£Šã‚ŒãŸæ§‹æˆãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬æ´—ã„å‡ºã—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
structure["structure"] ã¾ãŸã¯ structure["gemini_output"] ã«æ ¼ç´ã•ã‚ŒãŸ
ä¸æ­£ãªJSONãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºãƒ»å ±å‘Šã™ã‚‹
"""

import json
import logging
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.utils.files import validate_json_string
from src.structure.utils import load_structure_by_id

def setup_logging():
    """ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(f'corrupted_structures_scan_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        ]
    )
    return logging.getLogger(__name__)

def get_data_directory() -> str:
    """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
    data_dir = os.getenv('AIDEX_DATA_DIR', 'data')
    return data_dir

def scan_structure_files() -> List[str]:
    """æ§‹é€ ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’å–å¾—"""
    logger = setup_logging()
    data_dir = get_data_directory()
    structure_files = []
    
    # è¤‡æ•°ã®å€™è£œãƒ‘ã‚¹ã‚’ç¢ºèª
    possible_paths = [
        os.path.join(data_dir, "default"),
        data_dir,
        "structures",
        "data"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            logger.info(f"ğŸ“‚ ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {path}")
            for root, dirs, files in os.walk(path):
                for file in files:
                    if file.endswith('.json') and not file.endswith('_history.json'):
                        file_path = os.path.join(root, file)
                        structure_id = file.replace('.json', '')
                        structure_files.append((structure_id, file_path))
    
    logger.info(f"ğŸ“‹ ç™ºè¦‹ã•ã‚ŒãŸæ§‹é€ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(structure_files)}")
    return structure_files

def analyze_structure_data(structure_id: str, file_path: str) -> Dict[str, Any]:
    """æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
    logger = setup_logging()
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            structure = json.load(f)
        
        analysis = {
            "structure_id": structure_id,
            "file_path": file_path,
            "file_size": os.path.getsize(file_path),
            "modified_time": datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
            "structure_field_analysis": None,
            "gemini_output_analysis": None,
            "overall_status": "unknown"
        }
        
        # structure["structure"]ã®åˆ†æ
        if "structure" in structure:
            structure_data = structure["structure"]
            analysis["structure_field_analysis"] = analyze_json_field(
                "structure", structure_data, structure_id
            )
        
        # structure["gemini_output"]ã®åˆ†æ
        if "gemini_output" in structure:
            gemini_output = structure["gemini_output"]
            analysis["gemini_output_analysis"] = analyze_gemini_output(
                gemini_output, structure_id
            )
        
        # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®åˆ¤å®š
        structure_status = analysis["structure_field_analysis"]["status"] if analysis["structure_field_analysis"] else "not_found"
        gemini_status = analysis["gemini_output_analysis"]["status"] if analysis["gemini_output_analysis"] else "not_found"
        
        if structure_status == "corrupted" or gemini_status == "corrupted":
            analysis["overall_status"] = "corrupted"
        elif structure_status == "valid" or gemini_status == "valid":
            analysis["overall_status"] = "valid"
        else:
            analysis["overall_status"] = "unknown"
        
        return analysis
        
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
        return {
            "structure_id": structure_id,
            "file_path": file_path,
            "error": f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "overall_status": "corrupted"
        }
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
        return {
            "structure_id": structure_id,
            "file_path": file_path,
            "error": f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "overall_status": "error"
        }

def analyze_json_field(field_name: str, field_data: Any, structure_id: str) -> Dict[str, Any]:
    """JSONãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åˆ†æ"""
    analysis = {
        "field_name": field_name,
        "data_type": type(field_data).__name__,
        "status": "unknown",
        "error_details": None,
        "data_preview": None
    }
    
    if field_data is None:
        analysis["status"] = "null"
        return analysis
    
    if isinstance(field_data, str):
        analysis["data_preview"] = field_data[:100] + "..." if len(field_data) > 100 else field_data
        
        # ä¸å®Œå…¨ãªJSONã®æ¤œå‡º
        field_data_trimmed = field_data.strip()
        if field_data_trimmed == "{":
            analysis["status"] = "corrupted"
            analysis["error_details"] = "ä¸å®Œå…¨ãªJSON: é–‹ãæ‹¬å¼§ã®ã¿"
            return analysis
        
        if field_data_trimmed == "}":
            analysis["status"] = "corrupted"
            analysis["error_details"] = "ä¸å®Œå…¨ãªJSON: é–‰ã˜æ‹¬å¼§ã®ã¿"
            return analysis
        
        if field_data_trimmed.startswith("{") and not field_data_trimmed.endswith("}"):
            analysis["status"] = "corrupted"
            analysis["error_details"] = "ä¸å®Œå…¨ãªJSON: é–‹ãæ‹¬å¼§ã®ã¿ï¼ˆé•·ã„æ–‡å­—åˆ—ï¼‰"
            return analysis
        
        if not field_data_trimmed.startswith("{") and field_data_trimmed.endswith("}"):
            analysis["status"] = "corrupted"
            analysis["error_details"] = "ä¸å®Œå…¨ãªJSON: é–‰ã˜æ‹¬å¼§ã®ã¿ï¼ˆé•·ã„æ–‡å­—åˆ—ï¼‰"
            return analysis
        
        # æ‹¬å¼§ã®å‡è¡¡ãƒã‚§ãƒƒã‚¯
        open_braces = field_data_trimmed.count('{')
        close_braces = field_data_trimmed.count('}')
        if open_braces != close_braces:
            analysis["status"] = "corrupted"
            analysis["error_details"] = f"æ‹¬å¼§ã®ä¸å‡è¡¡: é–‹ãæ‹¬å¼§{open_braces}å€‹ã€é–‰ã˜æ‹¬å¼§{close_braces}å€‹"
            return analysis
        
        # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®æ¤œå‡º
        unquoted_keys = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*:', field_data_trimmed)
        if unquoted_keys:
            analysis["status"] = "corrupted"
            analysis["error_details"] = f"æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼: {unquoted_keys}"
            return analysis
        
        # JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        validation_result = validate_json_string(field_data_trimmed)
        if validation_result["is_valid"]:
            analysis["status"] = "valid"
        else:
            analysis["status"] = "corrupted"
            analysis["error_details"] = validation_result["error"]
    
    elif isinstance(field_data, dict):
        analysis["status"] = "valid"
        analysis["data_preview"] = f"ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ{len(field_data)}å€‹ã®ã‚­ãƒ¼ï¼‰"
    
    elif isinstance(field_data, list):
        analysis["status"] = "valid"
        analysis["data_preview"] = f"é…åˆ—ï¼ˆ{len(field_data)}å€‹ã®è¦ç´ ï¼‰"
    
    else:
        analysis["status"] = "unknown"
        analysis["error_details"] = f"äºˆæœŸã—ãªã„ãƒ‡ãƒ¼ã‚¿å‹: {type(field_data)}"
    
    return analysis

def analyze_gemini_output(gemini_output: Any, structure_id: str) -> Dict[str, Any]:
    """gemini_outputãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åˆ†æ"""
    analysis = {
        "field_name": "gemini_output",
        "data_type": type(gemini_output).__name__,
        "status": "unknown",
        "error_details": None,
        "content_analysis": None
    }
    
    if gemini_output is None:
        analysis["status"] = "null"
        return analysis
    
    if isinstance(gemini_output, dict):
        # contentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åˆ†æ
        if "content" in gemini_output:
            content_analysis = analyze_json_field("content", gemini_output["content"], structure_id)
            analysis["content_analysis"] = content_analysis
            
            if content_analysis["status"] == "corrupted":
                analysis["status"] = "corrupted"
                analysis["error_details"] = f"contentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç ´æ: {content_analysis['error_details']}"
            elif content_analysis["status"] == "valid":
                analysis["status"] = "valid"
            else:
                analysis["status"] = content_analysis["status"]
        
        # extracted_jsonãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åˆ†æ
        elif "extracted_json" in gemini_output:
            extracted_analysis = analyze_json_field("extracted_json", gemini_output["extracted_json"], structure_id)
            analysis["content_analysis"] = extracted_analysis
            
            if extracted_analysis["status"] == "corrupted":
                analysis["status"] = "corrupted"
                analysis["error_details"] = f"extracted_jsonãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç ´æ: {extracted_analysis['error_details']}"
            elif extracted_analysis["status"] == "valid":
                analysis["status"] = "valid"
            else:
                analysis["status"] = extracted_analysis["status"]
        
        else:
            analysis["status"] = "unknown"
            analysis["error_details"] = "contentã¾ãŸã¯extracted_jsonãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    
    else:
        analysis["status"] = "unknown"
        analysis["error_details"] = f"äºˆæœŸã—ãªã„ãƒ‡ãƒ¼ã‚¿å‹: {type(gemini_output)}"
    
    return analysis

def generate_report(analyses: List[Dict[str, Any]]) -> str:
    """åˆ†æçµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    total_count = len(analyses)
    corrupted_count = sum(1 for a in analyses if a.get("overall_status") == "corrupted")
    valid_count = sum(1 for a in analyses if a.get("overall_status") == "valid")
    error_count = sum(1 for a in analyses if a.get("overall_status") == "error")
    unknown_count = total_count - corrupted_count - valid_count - error_count
    
    report = f"""
# å£Šã‚ŒãŸæ§‹æˆãƒ‡ãƒ¼ã‚¿ ã‚¹ã‚­ãƒ£ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ
ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}

## æ¦‚è¦
- ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_count}
- ç ´æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {corrupted_count}
- æ­£å¸¸ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {valid_count}
- ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {error_count}
- ä¸æ˜ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {unknown_count}

## ç ´æãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°
"""
    
    corrupted_files = [a for a in analyses if a.get("overall_status") == "corrupted"]
    for analysis in corrupted_files:
        report += f"""
### {analysis['structure_id']}
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {analysis['file_path']}
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {analysis.get('file_size', 'N/A')} bytes
- æœ€çµ‚æ›´æ–°: {analysis.get('modified_time', 'N/A')}

"""
        
        if analysis.get("structure_field_analysis"):
            sa = analysis["structure_field_analysis"]
            report += f"- structureãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {sa['status']}"
            if sa.get("error_details"):
                report += f" - {sa['error_details']}"
            report += "\n"
        
        if analysis.get("gemini_output_analysis"):
            ga = analysis["gemini_output_analysis"]
            report += f"- gemini_outputãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {ga['status']}"
            if ga.get("error_details"):
                report += f" - {ga['error_details']}"
            report += "\n"
    
    # ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ï¼ˆCSVå½¢å¼ï¼‰
    report += f"""
## ç ´æãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆCSVå½¢å¼ï¼‰
structure_id,file_path,file_size,modified_time,structure_status,gemini_output_status,error_details
"""
    
    for analysis in corrupted_files:
        structure_status = analysis.get("structure_field_analysis", {}).get("status", "not_found")
        gemini_status = analysis.get("gemini_output_analysis", {}).get("status", "not_found")
        error_details = ""
        
        if analysis.get("structure_field_analysis", {}).get("error_details"):
            error_details += f"structure: {analysis['structure_field_analysis']['error_details']}; "
        if analysis.get("gemini_output_analysis", {}).get("error_details"):
            error_details += f"gemini_output: {analysis['gemini_output_analysis']['error_details']}"
        
        report += f"{analysis['structure_id']},{analysis['file_path']},{analysis.get('file_size', 'N/A')},{analysis.get('modified_time', 'N/A')},{structure_status},{gemini_status},\"{error_details}\"\n"
    
    return report

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    logger = setup_logging()
    logger.info("ğŸš€ å£Šã‚ŒãŸæ§‹æˆãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹")
    
    # æ§‹é€ ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’å–å¾—
    structure_files = scan_structure_files()
    
    if not structure_files:
        logger.warning("âš ï¸ æ§‹é€ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
    analyses = []
    for i, (structure_id, file_path) in enumerate(structure_files, 1):
        logger.info(f"ğŸ“‹ åˆ†æä¸­ ({i}/{len(structure_files)}): {structure_id}")
        analysis = analyze_structure_data(structure_id, file_path)
        analyses.append(analysis)
        
        # ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯è©³ç´°ãƒ­ã‚°
        if analysis.get("overall_status") == "corrupted":
            logger.warning(f"âš ï¸ ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {structure_id}")
            if analysis.get("structure_field_analysis", {}).get("error_details"):
                logger.warning(f"  - structure: {analysis['structure_field_analysis']['error_details']}")
            if analysis.get("gemini_output_analysis", {}).get("error_details"):
                logger.warning(f"  - gemini_output: {analysis['gemini_output_analysis']['error_details']}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    report = generate_report(analyses)
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"corrupted_structures_report_{timestamp}.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report)
    
    logger.info(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")
    
    # çµæœã‚’è¡¨ç¤º
    corrupted_count = sum(1 for a in analyses if a.get("overall_status") == "corrupted")
    logger.info(f"ğŸ“Š ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: ç ´æãƒ•ã‚¡ã‚¤ãƒ« {corrupted_count}å€‹ ã‚’æ¤œå‡º")
    
    if corrupted_count > 0:
        logger.warning("âš ï¸ ç ´æãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return False
    else:
        logger.info("âœ… ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return True

if __name__ == "__main__":
    import re
    success = main()
    sys.exit(0 if success else 1) 