"""
æ§‹é€ å±¥æ­´ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€æ§‹é€ ã®è©•ä¾¡ãƒ»è£œå®Œãƒ»ä¿å­˜æ“ä½œã®å±¥æ­´ã‚’ç®¡ç†ã—ã¾ã™ã€‚
"""

import json
import logging
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)

def get_data_dir() -> str:
    """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°AIDEX_DATA_DIRã‚’å„ªå…ˆï¼‰"""
    return os.environ.get('AIDEX_DATA_DIR', 'data')

def save_structure_history(
    structure_id: str, 
    role: str, 
    source: str, 
    content: str, 
    module_id: str = ""
) -> bool:
    """
    æ§‹é€ å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹
    
    Args:
        structure_id (str): æ§‹é€ ID
        role (str): æ“ä½œè€…ã®å½¹å‰²ï¼ˆuser, claude, geminiç­‰ï¼‰
        source (str): æ“ä½œã®ç¨®é¡ï¼ˆsave_structure, structure_evaluation, structure_completionç­‰ï¼‰
        content (str): ä¿å­˜ã™ã‚‹å†…å®¹
        module_id (str): ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
    Returns:
        bool: ä¿å­˜æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        # å±¥æ­´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        data_dir = get_data_dir()
        history_path = Path(f"{data_dir}/history")
        history_path.mkdir(parents=True, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        file_path = history_path / f"{structure_id}.json"
        
        # æ—¢å­˜å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ or åˆæœŸåŒ–
        if file_path.exists():
            try:
                with file_path.open("r", encoding="utf-8") as f:
                    data = json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.warning(f"æ—¢å­˜å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                data = _create_initial_history_data(structure_id, module_id)
        else:
            data = _create_initial_history_data(structure_id, module_id)
        
        # æ–°ã—ã„å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ 
        history_entry = {
            "role": role,
            "source": source,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        
        data["history"].append(history_entry)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with file_path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"[HISTORY] Saved: {structure_id} ({role}, {source})")
        return True
        
    except Exception as e:
        logger.error(f"å±¥æ­´ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return False

def save_evaluation_completion_history(structure: Dict[str, Any]) -> bool:
    """
    Claudeè©•ä¾¡ã¨Geminiè£œå®Œã®å±¥æ­´ã‚’JSONå½¢å¼ã§æ°¸ç¶šåŒ–ã™ã‚‹
    
    Args:
        structure (Dict[str, Any]): æ§‹é€ ãƒ‡ãƒ¼ã‚¿ï¼ˆevaluationsã¨completionsã‚’å«ã‚€ï¼‰
        
    Returns:
        bool: ä¿å­˜æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        structure_id = structure.get("id")
        if not structure_id:
            logger.error("æ§‹é€ IDãŒã‚ã‚Šã¾ã›ã‚“")
            return False
            
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        history_dir = Path("logs/structure_history")
        history_dir.mkdir(parents=True, exist_ok=True)
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{structure_id}_{timestamp}.json"
        file_path = history_dir / filename
        
        # ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        history_data = {
            "structure_id": structure_id,
            "timestamp": datetime.now().isoformat(),
            "evaluations": structure.get("evaluations", []),
            "completions": structure.get("completions", [])
        }
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with file_path.open("w", encoding="utf-8") as f:
            json.dump(history_data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"âœ… è©•ä¾¡ãƒ»è£œå®Œå±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {file_path}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ è©•ä¾¡ãƒ»è£œå®Œå±¥æ­´ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return False

def load_evaluation_completion_history(structure_id: str) -> List[Dict[str, Any]]:
    """
    æŒ‡å®šã•ã‚ŒãŸæ§‹é€ IDã®è©•ä¾¡ãƒ»è£œå®Œå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        structure_id (str): æ§‹é€ ID
        
    Returns:
        List[Dict[str, Any]]: å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    try:
        history_dir = Path("logs/structure_history")
        if not history_dir.exists():
            return []
            
        # æ§‹é€ IDã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        history_files = list(history_dir.glob(f"{structure_id}_*.json"))
        history_files.sort(reverse=True)  # æ–°ã—ã„é †
        
        histories = []
        for file_path in history_files:
            try:
                with file_path.open("r", encoding="utf-8") as f:
                    history_data = json.load(f)
                    histories.append(history_data)
            except (json.JSONDecodeError, IOError) as e:
                logger.warning(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {file_path}, error: {e}")
                
        logger.info(f"ğŸ“– è©•ä¾¡ãƒ»è£œå®Œå±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(histories)}ä»¶")
        return histories
        
    except Exception as e:
        logger.error(f"âŒ è©•ä¾¡ãƒ»è£œå®Œå±¥æ­´èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return []

def _create_initial_history_data(structure_id: str, module_id: str = "") -> Dict[str, Any]:
    """
    åˆæœŸå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹
    
    Args:
        structure_id (str): æ§‹é€ ID
        module_id (str): ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ID
        
    Returns:
        Dict[str, Any]: åˆæœŸå±¥æ­´ãƒ‡ãƒ¼ã‚¿
    """
    return {
        "structure_id": structure_id,
        "module_id": module_id,
        "timestamp": datetime.now().isoformat(),
        "history": []
    }

def load_structure_history(structure_id: str) -> Optional[Dict[str, Any]]:
    """
    æ§‹é€ å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        structure_id (str): æ§‹é€ ID
        
    Returns:
        Optional[Dict[str, Any]]: å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã€å­˜åœ¨ã—ãªã„å ´åˆã¯None
    """
    try:
        file_path = Path("data/history") / f"{structure_id}.json"
        if not file_path.exists():
            return None
            
        with file_path.open("r", encoding="utf-8") as f:
            return json.load(f)
            
    except Exception as e:
        logger.error(f"å±¥æ­´èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return None

def get_history_summary(structure_id: str) -> Dict[str, Any]:
    """
    æ§‹é€ å±¥æ­´ã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—ã™ã‚‹
    
    Args:
        structure_id (str): æ§‹é€ ID
        
    Returns:
        Dict[str, Any]: å±¥æ­´ã‚µãƒãƒªãƒ¼
    """
    history_data = load_structure_history(structure_id)
    if not history_data:
        return {
            "structure_id": structure_id,
            "total_entries": 0,
            "last_updated": None,
            "roles": [],
            "sources": []
        }
    
    history = history_data.get("history", [])
    roles = list(set(entry.get("role", "") for entry in history))
    sources = list(set(entry.get("source", "") for entry in history))
    
    return {
        "structure_id": structure_id,
        "total_entries": len(history),
        "last_updated": history[-1].get("timestamp") if history else None,
        "roles": roles,
        "sources": sources
    }

def cleanup_old_history(days_to_keep: int = 30) -> int:
    """
    å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
    
    Args:
        days_to_keep (int): ä¿æŒã™ã‚‹æ—¥æ•°
        
    Returns:
        int: å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    """
    try:
        history_path = Path("data/history")
        if not history_path.exists():
            return 0
            
        cutoff_time = datetime.now().timestamp() - (days_to_keep * 24 * 60 * 60)
        deleted_count = 0
        
        for file_path in history_path.glob("*.json"):
            if file_path.stat().st_mtime < cutoff_time:
                file_path.unlink()
                deleted_count += 1
                logger.info(f"å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {file_path}")
        
        return deleted_count
        
    except Exception as e:
        logger.error(f"å±¥æ­´ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return 0

def get_history_diff_data(structure_id: str, index: int = 0) -> Optional[Dict[str, Any]]:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã¨ãã®å‰ã®å±¥æ­´ã¨ã®å·®åˆ†ã‚’å–å¾—ã™ã‚‹
    
    Args:
        structure_id (str): æ§‹é€ ID
        index (int): å±¥æ­´ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0ãŒæœ€æ–°ï¼‰
        
    Returns:
        Optional[Dict[str, Any]]: å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã€å­˜åœ¨ã—ãªã„å ´åˆã¯None
    """
    try:
        # å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
        histories = load_evaluation_completion_history(structure_id)
        if not histories:
            return None
            
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if index < 0 or index >= len(histories):
            return None
            
        current_history = histories[index]
        
        # å‰ã®å±¥æ­´ã‚’å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        previous_history = histories[index + 1] if index + 1 < len(histories) else None
        
        # å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
        diff_data = {
            "current_content": current_history,
            "previous_content": previous_history,
            "timestamp": current_history.get("timestamp"),
            "source": "evaluation_completion",
            "index": index,
            "total_count": len(histories),
            "has_previous": previous_history is not None,
            "has_next": index > 0
        }
        
        logger.info(f"ğŸ“Š å±¥æ­´å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {structure_id}, index={index}")
        return diff_data
        
    except Exception as e:
        logger.error(f"âŒ å±¥æ­´å·®åˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return None

class StructureHistoryManager:
    """æ§‹æˆè©•ä¾¡å±¥æ­´ã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir: str = "data/history"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.max_history_count = 50  # å±¥æ­´ã®æœ€å¤§ä¿æŒä»¶æ•°
    
    def save_structure_history(self, structure_id: str, history_entry: Dict[str, Any]) -> bool:
        """
        æ§‹æˆè©•ä¾¡å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹
        
        Args:
            structure_id: æ§‹æˆID
            history_entry: å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªï¼ˆtimestamp, structure_before, structure_after, evaluation_resultï¼‰
            
        Returns:
            bool: ä¿å­˜æˆåŠŸæ™‚True
        """
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‚’è¨­å®š
            if 'timestamp' not in history_entry:
                history_entry['timestamp'] = datetime.now().isoformat()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            history_file = self.data_dir / f"{structure_id}.json"
            
            # æ—¢å­˜ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
            existing_history = self.load_structure_history(structure_id)
            
            # æ–°ã—ã„å±¥æ­´ã‚’è¿½åŠ 
            existing_history.append(history_entry)
            
            # å±¥æ­´æ•°ãŒä¸Šé™ã‚’è¶…ãˆãŸå ´åˆã€å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            if len(existing_history) > self.max_history_count:
                existing_history = existing_history[-self.max_history_count:]
                logger.info(f"å±¥æ­´æ•°ãŒä¸Šé™({self.max_history_count}ä»¶)ã‚’è¶…ãˆãŸãŸã‚ã€å¤ã„å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(existing_history, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"âœ… æ§‹æˆè©•ä¾¡å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ - structure_id: {structure_id}, å±¥æ­´æ•°: {len(existing_history)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ§‹æˆè©•ä¾¡å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ - structure_id: {structure_id}, error: {str(e)}")
            return False
    
    def load_structure_history(self, structure_id: str) -> List[Dict[str, Any]]:
        """
        æ§‹æˆè©•ä¾¡å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            structure_id: æ§‹æˆID
            
        Returns:
            List[Dict[str, Any]]: å±¥æ­´ãƒªã‚¹ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        """
        try:
            history_file = self.data_dir / f"{structure_id}.json"
            
            if not history_file.exists():
                logger.info(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ - {history_file}")
                return []
            
            with open(history_file, 'r', encoding='utf-8') as f:
                history_data = json.load(f)
            
            # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
            history_data.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            logger.info(f"âœ… æ§‹æˆè©•ä¾¡å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ - structure_id: {structure_id}, å±¥æ­´æ•°: {len(history_data)}")
            return history_data
            
        except Exception as e:
            logger.error(f"âŒ æ§‹æˆè©•ä¾¡å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ - structure_id: {structure_id}, error: {str(e)}")
            return []
    
    def get_history_summary(self, structure_id: str) -> Dict[str, Any]:
        """
        å±¥æ­´ã®ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’å–å¾—
        
        Args:
            structure_id: æ§‹æˆID
            
        Returns:
            Dict[str, Any]: ã‚µãƒãƒªãƒ¼æƒ…å ±
        """
        history = self.load_structure_history(structure_id)
        
        if not history:
            return {
                'total_count': 0,
                'latest_timestamp': None,
                'providers': [],
                'average_score': None
            }
        
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ã®çµ±è¨ˆ
        providers = {}
        scores = []
        
        for entry in history:
            eval_result = entry.get('evaluation_result', {})
            provider = eval_result.get('provider', 'unknown')
            
            if provider not in providers:
                providers[provider] = 0
            providers[provider] += 1
            
            # ã‚¹ã‚³ã‚¢ã®åé›†
            score = eval_result.get('score')
            if score is not None and isinstance(score, (int, float)):
                scores.append(score)
        
        return {
            'total_count': len(history),
            'latest_timestamp': history[0].get('timestamp') if history else None,
            'providers': list(providers.keys()),
            'provider_counts': providers,
            'average_score': sum(scores) / len(scores) if scores else None,
            'score_count': len(scores)
        }
    
    def delete_history(self, structure_id: str) -> bool:
        """
        æŒ‡å®šã•ã‚ŒãŸæ§‹æˆã®å±¥æ­´ã‚’å‰Šé™¤
        
        Args:
            structure_id: æ§‹æˆID
            
        Returns:
            bool: å‰Šé™¤æˆåŠŸæ™‚True
        """
        try:
            history_file = self.data_dir / f"{structure_id}.json"
            
            if history_file.exists():
                history_file.unlink()
                logger.info(f"âœ… æ§‹æˆè©•ä¾¡å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã—ãŸ - structure_id: {structure_id}")
                return True
            else:
                logger.info(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ - structure_id: {structure_id}")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ§‹æˆè©•ä¾¡å±¥æ­´ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ - structure_id: {structure_id}, error: {str(e)}")
            return False
    
    def cleanup_old_histories(self, days_to_keep: int = 30) -> int:
        """
        å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        
        Args:
            days_to_keep: ä¿æŒã™ã‚‹æ—¥æ•°
            
        Returns:
            int: å‰Šé™¤ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
        """
        try:
            cutoff_time = datetime.now().timestamp() - (days_to_keep * 24 * 60 * 60)
            deleted_count = 0
            
            for history_file in self.data_dir.glob("*.json"):
                if history_file.stat().st_mtime < cutoff_time:
                    history_file.unlink()
                    deleted_count += 1
                    logger.info(f"å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {history_file}")
            
            logger.info(f"âœ… å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº† - å‰Šé™¤æ•°: {deleted_count}")
            return deleted_count
            
        except Exception as e:
            logger.error(f"âŒ å¤ã„å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸ - error: {str(e)}")
            return 0

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
history_manager = StructureHistoryManager()

def save_evaluation_history(structure_id: str, history_entry: Dict[str, Any]) -> bool:
    """è©•ä¾¡å±¥æ­´ä¿å­˜ã®ç°¡æ˜“é–¢æ•°"""
    return history_manager.save_structure_history(structure_id, history_entry)

def load_evaluation_history(structure_id: str) -> List[Dict[str, Any]]:
    """è©•ä¾¡å±¥æ­´èª­ã¿è¾¼ã¿ã®ç°¡æ˜“é–¢æ•°"""
    return history_manager.load_structure_history(structure_id)

def get_evaluation_history_summary(structure_id: str) -> Dict[str, Any]:
    """è©•ä¾¡å±¥æ­´ã‚µãƒãƒªãƒ¼å–å¾—ã®ç°¡æ˜“é–¢æ•°"""
    return history_manager.get_history_summary(structure_id) 