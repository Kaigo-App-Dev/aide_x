"""
Gemini AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€Googleã®Geminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import logging
from google import generativeai as genai
from src.llm.providers.base import BaseLLMProvider, ChatMessage
from src.llm.providers.types import AIProviderResponse
from src.exceptions import GeminiAPIError, PromptNotFoundError, ResponseFormatError, APIRequestError
from src.utils.logging import save_log
from src.llm.prompts.manager import PromptManager
from src.llm.prompts.prompt import Prompt
from src.structure_feedback_engine import StructureFeedbackEngine
import os
import json
import requests
import re
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime
import yaml
from src.exceptions import ProviderInitializationError, APIKeyMissingError
from copy import deepcopy

logger = logging.getLogger(__name__)

def safe_yaml_to_json(yaml_str: str) -> Dict[str, Any]:
    """YAMLæ–‡å­—åˆ—ã‚’å®‰å…¨ã«JSONã«å¤‰æ›ã™ã‚‹"""
    try:
        # YAMLã‚’ãƒ‘ãƒ¼ã‚¹
        data = yaml.safe_load(yaml_str)
        # JSONã«å¤‰æ›ã—ã¦æ¤œè¨¼
        json_str = json.dumps(data)
        return json.loads(json_str)
    except Exception as e:
        logger.error(f"YAML to JSON conversion failed: {e}")
        return {}

def fix_unquoted_keys(json_str: str) -> str:
    """
    æœªã‚¯ã‚ªãƒ¼ãƒˆã®JSONã‚­ãƒ¼ã‚’ä¿®æ­£ã™ã‚‹
    
    Args:
        json_str (str): ä¿®æ­£å¯¾è±¡ã®JSONæ–‡å­—åˆ—
        
    Returns:
        str: ä¿®æ­£å¾Œã®JSONæ–‡å­—åˆ—
    """
    # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«å†…ã®ã‚³ãƒ­ãƒ³ã‚’ä¿è­·
    protected_str = re.sub(r'"[^"]*"', lambda m: m.group(0).replace(':', '\\u003A'), json_str)
    
    # æœªã‚¯ã‚ªãƒ¼ãƒˆã®ã‚­ãƒ¼ã‚’æ¤œå‡ºã—ã¦ä¿®æ­£
    # 1. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é–‹å§‹ï¼ˆ{ï¼‰ã¾ãŸã¯ã‚«ãƒ³ãƒžï¼ˆ,ï¼‰ã®å¾Œã«ç¶šã
    # 2. ä»»æ„ã®ç©ºç™½æ–‡å­—
    # 3. æœ‰åŠ¹ãªã‚­ãƒ¼åï¼ˆè‹±æ•°å­—ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã€ãƒã‚¤ãƒ•ãƒ³ï¼‰
    # 4. ä»»æ„ã®ç©ºç™½æ–‡å­—
    # 5. ã‚³ãƒ­ãƒ³ï¼ˆ:ï¼‰
    pattern = r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_\-]*)\s*:'
    
    # ã‚­ãƒ¼ã‚’ã‚¯ã‚ªãƒ¼ãƒˆã§å›²ã‚€
    fixed = re.sub(pattern, r'\1"\2":', protected_str)
    
    # ä¿è­·ã—ãŸæ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’å…ƒã«æˆ»ã™
    fixed = fixed.replace('\\u003A', ':')
    
    return fixed

def extract_json_part(text: str) -> Dict[str, Any]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦è§£æžã™ã‚‹ï¼ˆsrc/utils/files.pyã®extract_json_partã‚’ä½¿ç”¨ï¼‰
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        Dict[str, Any]: æŠ½å‡ºã•ã‚ŒãŸJSONã€å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€è¾žæ›¸
    """
    try:
        # src/utils/files.pyã®extract_json_partã‚’ä½¿ç”¨
        from src.utils.files import extract_json_part as files_extract_json_part
        return files_extract_json_part(text)
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«ä¿å­˜
        error_dump = {
            "original_text": text,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        dump_path = f"logs/gemini_error_dump_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs("logs", exist_ok=True)
        with open(dump_path, "w", encoding="utf-8") as f:
            json.dump(error_dump, f, ensure_ascii=False, indent=2)
        logger.error(f"JSON extraction failed: {e}")
        return {
            "error": "JSONæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ",
            "reason": str(e),
            "original_text": text[:200] + "..." if len(text) > 200 else text
        }

class GeminiProvider(BaseLLMProvider):
    """Gemini AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, prompt_manager: PromptManager, api_key: Optional[str] = None):
        """
        GeminiProviderã®åˆæœŸåŒ–
        
        Args:
            prompt_manager (PromptManager): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆå¿…é ˆï¼‰
            api_key (Optional[str]): Google APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°GEMINI_API_KEYã‹ã‚‰ã‚‚å–å¾—å¯èƒ½ï¼‰
            
        Raises:
            ProviderInitializationError: prompt_managerãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
            APIKeyMissingError: APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        """
        if prompt_manager is None:
            error_msg = "PromptManager instance is required"
            logger.error(error_msg)
            raise ProviderInitializationError("gemini", error_msg)
        self.prompt_manager = prompt_manager
        
        # APIã‚­ãƒ¼ã®å–å¾—ï¼ˆå„ªå…ˆé †ä½: å¼•æ•° > GEMINI_API_KEY > GOOGLE_API_KEYï¼‰
        self.api_key = api_key or os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        
        # APIã‚­ãƒ¼ã®è©³ç´°ãƒ­ã‚°
        logger.debug(f"ðŸ”‘ Gemini APIã‚­ãƒ¼ç¢ºèª:")
        logger.debug(f"  - å¼•æ•°æŒ‡å®š: {'ã‚ã‚Š' if api_key else 'ãªã—'}")
        logger.debug(f"  - GEMINI_API_KEY: {'è¨­å®šæ¸ˆã¿' if os.getenv('GEMINI_API_KEY') else 'æœªè¨­å®š'}")
        logger.debug(f"  - GOOGLE_API_KEY: {'è¨­å®šæ¸ˆã¿' if os.getenv('GOOGLE_API_KEY') else 'æœªè¨­å®š'}")
        logger.debug(f"  - æœ€çµ‚ä½¿ç”¨ã‚­ãƒ¼: {'è¨­å®šæ¸ˆã¿' if self.api_key else 'æœªè¨­å®š'}")
        
        if not self.api_key:
            error_msg = "GEMINI_API_KEY or GOOGLE_API_KEY environment variable is not set"
            logger.error(error_msg)
            raise APIKeyMissingError("gemini", ["GEMINI_API_KEY", "GOOGLE_API_KEY"])
        
        try:
            # Call parent constructor first
            super().__init__(model="gemini-1.5-flash")
            
            # Gemini APIã®è¨­å®š
            genai.configure(api_key=self.api_key)
            self.model_name = "gemini-1.5-flash"
            # Set the actual model instance after parent constructor
            self.model = genai.GenerativeModel(self.model_name)
            self.feedback_engine = StructureFeedbackEngine()
            logger.info("âœ… GeminiProvider initialized with PromptManager and API Key")
            logger.debug(f"ðŸŽ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
        except Exception as e:
            error_msg = f"Failed to initialize Gemini model: {str(e)}"
            logger.error(error_msg)
            raise ProviderInitializationError("gemini", error_msg)
    
    def generate_response(self, prompt: str, **kwargs) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            prompt (str): å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            **kwargs: è¿½åŠ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
        """
        try:
            logger.debug(f"ðŸŽ¯ Gemini generate_responseé–‹å§‹")
            logger.debug(f"ðŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:200]}...")
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=kwargs.get("temperature", 0.7),
                    max_output_tokens=kwargs.get("max_tokens", 1024)
                )
            )
            
            if not response or not getattr(response, "text", None):
                error_msg = "Gemini: Response format error - response is None or has no text"
                logger.error(error_msg)
                raise ResponseFormatError(error_msg)
            
            response_text = response.text
            logger.debug(f"âœ… Gemini generate_responseæˆåŠŸ - æ–‡å­—æ•°: {len(response_text)}")
            
            return response_text
            
        except Exception as e:
            error_msg = f"Gemini: generate_response error: {str(e)}"
            logger.error(error_msg)
            raise ResponseFormatError(error_msg)
    
    def get_template(self, template_name: str) -> Optional[str]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        
        Args:
            template_name (str): ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
            
        Returns:
            Optional[str]: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡å­—åˆ—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯None
        """
        return self.prompt_manager.get_template("gemini", template_name)

    def call(self, prompt: str, **kwargs) -> AIProviderResponse:
        """Gemini APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”ã‚’è¿”ã™"""
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã®ä¿å­˜
            save_log(
                "Gemini API request",
                logging.INFO,
                {
                    "model": self.model_name,
                    "prompt": prompt,
                    "temperature": kwargs.get("temperature", 0.7),
                    "max_tokens": kwargs.get("max_tokens", 1024)
                }
            )
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=kwargs.get("temperature", 0.7),
                    max_output_tokens=kwargs.get("max_tokens", 1024)
                )
            )
            
            if not response or not response.text:
                raise ResponseFormatError("Gemini: Response format error.")
            
            content = response.text
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
            if kwargs.get("expect_json", False):
                try:
                    # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                    extracted_json = extract_json_part(content)
                    if not extracted_json:
                        raise ResponseFormatError("Gemini: Failed to extract valid JSON from response.")
                    
                    # æ§‹é€ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦JSONã‚’å‡¦ç†
                    reference_json = kwargs.get("reference_json")
                    if reference_json:
                        result = self.feedback_engine.process_structure(
                            json.dumps(extracted_json),
                            reference_json
                        )
                    else:
                        result = extracted_json
                    
                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã®ä¿å­˜
                    save_log(
                        "Gemini API response",
                        logging.INFO,
                        {
                            "model": self.model_name,
                            "result": result,
                            "raw": str(response)
                        }
                    )
                    
                    return AIProviderResponse(
                        content=json.dumps(result),
                        raw=response,
                        provider="gemini",
                        error=None
                    )
                except Exception as e:
                    raise ResponseFormatError(f"Gemini: Failed to process JSON response: {str(e)}")
            
            # é€šå¸¸ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ­ã‚°ä¿å­˜
            save_log(
                "Gemini API response",
                logging.INFO,
                {
                    "model": self.model_name,
                    "result": content,
                    "raw": str(response)
                }
            )
            
            return AIProviderResponse(
                content=content,
                raw=response,
                provider="gemini",
                error=None
            )
        except ResponseFormatError as e:
            error_msg = f"Gemini: Response format error: {str(e)}"
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": self.model_name,
                    "error": error_msg,
                    "prompt": prompt
                }
            )
            return AIProviderResponse(
                content="",
                raw=None,
                provider="gemini",
                error=error_msg
            )
        except Exception as e:
            error_msg = f"Gemini: API request error: {str(e)}"
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": self.model_name,
                    "error": error_msg,
                    "prompt": prompt
                }
            )
            return AIProviderResponse(
                content="",
                raw=None,
                provider="gemini",
                error=error_msg
            )

    def chat(self, prompt: 'Prompt', model_name: str, prompt_manager: 'PromptManager', **kwargs) -> str:
        """
        Geminiç”¨ã®çµ±ä¸€chatã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        Args:
            prompt (Prompt): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            model_name (str): ãƒ¢ãƒ‡ãƒ«å
            prompt_manager (PromptManager): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒžãƒãƒ¼ã‚¸ãƒ£
            **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
        """
        try:
            prompt_str = prompt.format(**kwargs)
            
            # è©³ç´°ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’å‡ºåŠ›
            logger.info(f"ðŸŽ¯ Geminiè£œå®Œé–‹å§‹ - model: {model_name}")
            logger.info(f"ðŸ“ Geminiãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡:")
            logger.info(f"{'='*50}")
            logger.info(f"{prompt_str}")
            logger.info(f"{'='*50}")
            
            # APIã‚­ãƒ¼ã®ç¢ºèª
            api_key = os.getenv("GEMINI_API_KEY")
            logger.info(f"ðŸ” APIã‚­ãƒ¼ç¢ºèª: {'è¨­å®šæ¸ˆã¿' if api_key else 'æœªè¨­å®š'}")
            if api_key:
                logger.debug(f"ðŸ”‘ APIã‚­ãƒ¼é•·: {len(api_key)}æ–‡å­—")
            else:
                raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            save_log(
                "Gemini API request",
                logging.INFO,
                {
                    "model": model_name,
                    "prompt": prompt_str,
                    "prompt_length": len(prompt_str),
                    "kwargs": kwargs,
                    "api_key_set": bool(api_key)
                }
            )
            
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è©³ç´°ãƒ­ã‚°
            logger.info(f"ðŸ”— Gemini APIå‘¼ã³å‡ºã—:")
            logger.info(f"  - ãƒ¢ãƒ‡ãƒ«: {model_name}")
            logger.info(f"  - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt_str)}")
            logger.info(f"  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {kwargs}")
            logger.info("ðŸ“¡ Gemini APIé€ä¿¡ä¸­...")
            
            response = self.model.generate_content(
                prompt_str,
                generation_config=genai.types.GenerationConfig(
                    temperature=kwargs.get("temperature", 0.7),
                    max_output_tokens=kwargs.get("max_tokens", 1024)
                )
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ãƒ­ã‚°
            logger.info("âœ… Gemini APIé€ä¿¡å®Œäº†")
            logger.debug(f"ðŸ“¡ Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹:")
            logger.debug(f"  - ãƒ¬ã‚¹ãƒãƒ³ã‚¹åž‹: {type(response)}")
            logger.debug(f"  - ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {str(response)[:200]}...")
            
            if not response or not getattr(response, "text", None):
                error_msg = "Gemini: Response format error - response is None or has no text"
                logger.error(error_msg)
                logger.error(f"âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°: {str(response)}")
                save_log(
                    "Gemini API error",
                    logging.ERROR,
                    {
                        "model": model_name,
                        "error": error_msg,
                        "response": str(response) if response else "None",
                        "response_type": str(type(response))
                    }
                )
                raise ResponseFormatError(error_msg)
            
            response_text = response.text
            logger.info(f"âœ… Geminiå¿œç­”å–å¾—æˆåŠŸ - æ–‡å­—æ•°: {len(response_text)}")
            logger.debug(f"ðŸ“„ Geminiç”Ÿå‡ºåŠ›:")
            logger.debug(f"{'='*50}")
            logger.debug(f"{response_text}")
            logger.debug(f"{'='*50}")
            
            save_log(
                "Gemini API response",
                logging.INFO,
                {
                    "model": model_name,
                    "result": response_text,
                    "result_length": len(response_text),
                    "raw_response": str(response)
                }
            )
            
            return response_text
            
        except ResponseFormatError as e:
            error_msg = f"Gemini: Response format error: {str(e)}"
            logger.error(error_msg)
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": model_name,
                    "error": error_msg,
                    "prompt": prompt_str if 'prompt_str' in locals() else "Unknown",
                    "error_type": "ResponseFormatError"
                }
            )
            # ä¾‹å¤–ã‚’å†ç™ºç”Ÿã•ã›ã‚‹ãŒã€Noneã¯è¿”ã•ãªã„
            raise
        except requests.RequestException as e:
            error_msg = f"Gemini: Network request error: {str(e)}"
            logger.error(error_msg)
            logger.error(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            logger.error(f"âŒ ä¾‹å¤–åž‹: {type(e).__name__}")
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": model_name,
                    "error": error_msg,
                    "prompt": prompt_str if 'prompt_str' in locals() else "Unknown",
                    "error_type": "RequestException",
                    "error_details": str(e)
                }
            )
            raise APIRequestError(error_msg)
        except json.JSONDecodeError as e:
            error_msg = f"Gemini: JSON decode error: {str(e)}"
            logger.error(error_msg)
            logger.error(f"âŒ JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            logger.error(f"âŒ ä¾‹å¤–åž‹: {type(e).__name__}")
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": model_name,
                    "error": error_msg,
                    "prompt": prompt_str if 'prompt_str' in locals() else "Unknown",
                    "error_type": "JSONDecodeError",
                    "error_details": str(e)
                }
            )
            raise ResponseFormatError(error_msg)
        except Exception as e:
            error_msg = f"Gemini: API request error: {str(e)}"
            logger.error(error_msg)
            logger.error(f"âŒ ä¾‹å¤–è©³ç´°: {str(e)}")
            logger.error(f"âŒ ä¾‹å¤–åž‹: {type(e).__name__}")
            import traceback
            logger.error(f"âŒ ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
            save_log(
                "Gemini API error",
                logging.ERROR,
                {
                    "model": model_name,
                    "error": error_msg,
                    "prompt": prompt_str if 'prompt_str' in locals() else "Unknown",
                    "error_type": type(e).__name__,
                    "error_details": str(e),
                    "stack_trace": traceback.format_exc()
                }
            )
            # ä¾‹å¤–ã‚’å†ç™ºç”Ÿã•ã›ã‚‹ãŒã€Noneã¯è¿”ã•ãªã„
            raise APIRequestError(error_msg)

def call_gemini_api(
    messages: List[Dict[str, str]],
    model: str = "gemini-1.5-flash",
    temperature: float = 0.8
) -> str:
    """
    Gemini APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹
    
    Args:
        messages (List[Dict[str, str]]): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
        model (str, optional): ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ "gemini-1.5-flash"
        temperature (float, optional): ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 0.8
        
    Returns:
        str: APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆ
             ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™
        
    Raises:
        ValueError: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    # APIã‚­ãƒ¼ã®å–å¾—
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        logger.warning("GEMINI_API_KEY environment variable is not set")
        return ""
    
    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    url = f"https://generativelanguage.googleapis.com/v1/models/{model}:generateContent?key={api_key}"
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json"
    }
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Geminiå½¢å¼ã«å¤‰æ›
    contents = []
    for msg in messages:
        if "role" in msg and "content" in msg:
            contents.append({
                "role": msg["role"],
                "parts": [{"text": msg["content"]}]
            })
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    data = {
        "contents": contents,
        "generationConfig": {
            "temperature": temperature
        }
    }
    
    try:
        # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å ´åˆã¯ä¾‹å¤–ã‚’ç™ºç”Ÿ
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æž
        result = response.json()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                parts = candidate["content"]["parts"]
                if len(parts) > 0 and "text" in parts[0]:
                    return parts[0]["text"]
        
        logger.warning("Invalid response format from Gemini API")
        return ""
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Gemini API request failed: {str(e)}")
        return ""
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse Gemini API response: {str(e)}")
        return ""
    except KeyError as e:
        logger.error(f"Missing key in Gemini API response: {str(e)}")
        return ""
    except Exception as e:
        logger.error(f"Unexpected error in Gemini API call: {str(e)}")
        return ""

__all__ = [
    'call_gemini_api'
] 