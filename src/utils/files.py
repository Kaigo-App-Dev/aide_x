"""
AIDE-X: ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ»JSONæŠ½å‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""
import json
import logging
import os
from datetime import datetime
from typing import Dict, Any, Optional
import re

logger = logging.getLogger(__name__)

def extract_json_part(text: str) -> Dict[str, Any]:
    """
    ChatGPTå¿œç­”ã‹ã‚‰JSONæ§‹æˆéƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    
    Args:
        text (str): ChatGPTå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        Dict[str, Any]: æŠ½å‡ºã•ã‚ŒãŸJSONãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æƒ…å ±
    """
    logger.info(f"ğŸ” extract_json_part: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆé•· = {len(text)}")
    
    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"logs/chatgpt_raw_output_{timestamp}.txt"
    try:
        os.makedirs("logs", exist_ok=True)
        with open(log_filename, "w", encoding="utf-8") as f:
            f.write(text)
        logger.info(f"ğŸ“ ChatGPTåŸæ–‡ã‚’ä¿å­˜: {log_filename}")
    except Exception as e:
        logger.warning(f"ChatGPTåŸæ–‡ã®ä¿å­˜ã«å¤±æ•—: {e}")
    
    # 1. ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®JSONã‚’æ¤œç´¢ï¼ˆæœ€å„ªå…ˆï¼‰
    code_block_pattern = r'```(?:json)?\s*\n([\s\S]*?)\n```'
    code_matches = re.findall(code_block_pattern, text)
    
    for json_str in code_matches:
        json_str = json_str.strip()
        if json_str.startswith('{') and json_str.endswith('}'):
            logger.info("ğŸ” extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONã‚’æŠ½å‡º")
            
            # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®æ¤œå‡ºã¨ä¿®å¾©
            json_str = repair_unquoted_keys(json_str)
            
            # JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            validation_result = validate_json_string(json_str)
            if validation_result["is_valid"]:
                logger.info("âœ… extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯JSONæŠ½å‡ºæˆåŠŸ")
                return validation_result["data"]
            else:
                logger.warning(f"ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {validation_result['error']}")
                # æ¬¡ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’è©¦è¡Œ
    
    # 2. å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œç´¢ï¼ˆæ‹¬å¼§ã®å‡è¡¡ã‚’è€ƒæ…®ï¼‰
    # ã‚ˆã‚Šæ­£ç¢ºãªJSONæŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
    def find_complete_json(text: str) -> Optional[str]:
        """å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
        start = 0
        while True:
            # é–‹ãæ‹¬å¼§ã‚’æ¢ã™
            open_pos = text.find('{', start)
            if open_pos == -1:
                break
            
            # ãã®ä½ç½®ã‹ã‚‰å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ§‹ç¯‰
            brace_count = 0
            pos = open_pos
            in_string = False
            escape_next = False
            
            while pos < len(text):
                char = text[pos]
                
                if escape_next:
                    escape_next = False
                elif char == '\\':
                    escape_next = True
                elif char == '"' and not escape_next:
                    in_string = not in_string
                elif not in_string:
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            # å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã£ãŸ
                            json_str = text[open_pos:pos + 1]
                            # åŸºæœ¬çš„ãªæ¤œè¨¼
                            if len(json_str) > 10:  # æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                                return json_str
                            break
                
                pos += 1
            
            start = open_pos + 1
        
        return None
    
    # å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œç´¢
    complete_json = find_complete_json(text)
    if complete_json:
        logger.info(f"ğŸ” extract_json_part: å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºï¼ˆé•·ã•: {len(complete_json)}ï¼‰")
        
        # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®æ¤œå‡ºã¨ä¿®å¾©
        complete_json = repair_unquoted_keys(complete_json)
        
        # æœ«å°¾ã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤
        complete_json = re.sub(r',(\s*[}\]])', r'\1', complete_json)
        
        # JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        validation_result = validate_json_string(complete_json)
        if validation_result["is_valid"]:
            logger.info("âœ… extract_json_part: å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŠ½å‡ºæˆåŠŸ")
            return validation_result["data"]
        else:
            logger.error(f"âŒ extract_json_part: å®Œå…¨ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {validation_result['error']}")
            logger.error(f"âŒ extract_json_part: å‡¦ç†å¾Œã®JSONæ–‡å­—åˆ— = {complete_json}")
            logger.error(f"âŒ extract_json_part: ã‚¨ãƒ©ãƒ¼ä½ç½®ã®è©³ç´°åˆ†æ:")
            
            # ã‚¨ãƒ©ãƒ¼ä½ç½®ã®è©³ç´°åˆ†æ
            try:
                json.loads(complete_json)
            except json.JSONDecodeError as json_error:
                logger.error(f"âŒ JSONDecodeErrorè©³ç´°:")
                logger.error(f"   - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {json_error.msg}")
                logger.error(f"   - ã‚¨ãƒ©ãƒ¼ä½ç½®: è¡Œ{json_error.lineno}, åˆ—{json_error.colno}")
                logger.error(f"   - ã‚¨ãƒ©ãƒ¼è¡Œã®å†…å®¹: {json_error.doc.split(chr(10))[json_error.lineno-1] if json_error.lineno > 0 else 'N/A'}")
                logger.error(f"   - ã‚¨ãƒ©ãƒ¼ä½ç½®ã®æ–‡å­—: '{json_error.doc[json_error.pos] if json_error.pos < len(json_error.doc) else 'N/A'}'")
            
            return {
                "error": "JSONæ§‹æˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ",
                "reason": f"JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {validation_result['error']}",
                "extracted_json_string": complete_json,
                "original_text": text[:200] + "..." if len(text) > 200 else text
            }
    
    # 3. ChatGPTå¿œç­”ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    chatgpt_patterns = [
        r'æ§‹æˆ[ï¼š:]\s*(\{[\s\S]*?\})',  # ã€Œæ§‹æˆ: {JSON}ã€å½¢å¼
        r'JSON[ï¼š:]\s*(\{[\s\S]*?\})',  # ã€ŒJSON: {JSON}ã€å½¢å¼
        r'æ§‹é€ [ï¼š:]\s*(\{[\s\S]*?\})',  # ã€Œæ§‹é€ : {JSON}ã€å½¢å¼
        r'ä»¥ä¸‹ã®æ§‹æˆ[ï¼š:]\s*(\{[\s\S]*?\})',  # ã€Œä»¥ä¸‹ã®æ§‹æˆ: {JSON}ã€å½¢å¼
    ]
    
    for pattern in chatgpt_patterns:
        match = re.search(pattern, text)
        if match:
            json_str = match.group(1).strip()
            logger.info(f"ğŸ” extract_json_part: ChatGPTç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰JSONã‚’æŠ½å‡ºï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern[:20]}...ï¼‰")
            
            # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®æ¤œå‡ºã¨ä¿®å¾©
            json_str = repair_unquoted_keys(json_str)
            
            # JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            validation_result = validate_json_string(json_str)
            if validation_result["is_valid"]:
                logger.info(f"âœ… extract_json_part: ChatGPTç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³JSONæŠ½å‡ºæˆåŠŸ")
                return validation_result["data"]
            else:
                logger.warning(f"ChatGPTç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®JSONãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {validation_result['error']}")
                # æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
    
    # 4. JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡º
    logger.info("ğŸ” JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºã‚’è©¦è¡Œ")
    extracted_structure = extract_structure_from_markdown(text)
    if extracted_structure:
        logger.info("âœ… Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºæˆåŠŸ")
        return extracted_structure
    
    # 5. æœ€çµ‚çš„ã«ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¿”ã™ï¼ˆè©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ï¼‰
    logger.error(f"âŒ extract_json_part: JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    logger.error(f"extract_json_part: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå…¨æ–‡ = {text}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆé•· = {len(text)}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®200æ–‡å­— = {text[:200]}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¾Œã®200æ–‡å­— = {text[-200:]}")
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´ã‚’åˆ†æ
    if "```" in text:
        logger.error(f"extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯å­˜åœ¨ã™ã‚‹ãŒã€JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„")
    if "{" in text and "}" in text:
        logger.error(f"extract_json_part: æ³¢æ‹¬å¼§ã¯å­˜åœ¨ã™ã‚‹ãŒã€æœ‰åŠ¹ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªã„")
    if "[" in text and "]" in text:
        logger.error(f"extract_json_part: è§’æ‹¬å¼§ï¼ˆé…åˆ—ï¼‰ã¯å­˜åœ¨ã™ã‚‹ãŒã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªã„")
    
    # ChatGPTå¿œç­”ç‰¹æœ‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    chatgpt_keywords = ["æ§‹æˆ", "JSON", "æ§‹é€ ", "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«", "æ©Ÿèƒ½"]
    found_keywords = [kw for kw in chatgpt_keywords if kw in text]
    if found_keywords:
        logger.error(f"extract_json_part: ChatGPTå¿œç­”ã‚‰ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º: {found_keywords}")
    
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
    return {
        "error": "JSONæ§‹æˆãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ",
        "reason": "ãƒ†ã‚­ã‚¹ãƒˆã«æœ‰åŠ¹ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“",
        "original_text": text[:200] + "..." if len(text) > 200 else text,
        "text_length": len(text),
        "found_keywords": found_keywords if 'found_keywords' in locals() else []
    }

def validate_json_string(json_str: str) -> Dict[str, Any]:
    """
    JSONæ–‡å­—åˆ—ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    
    Args:
        json_str (str): ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã®JSONæ–‡å­—åˆ—
        
    Returns:
        Dict[str, Any]: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
            - is_valid (bool): ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸãƒ•ãƒ©ã‚°
            - data (Dict[str, Any]): ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸJSONãƒ‡ãƒ¼ã‚¿ï¼ˆæˆåŠŸæ™‚ï¼‰
            - error (str): ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå¤±æ•—æ™‚ï¼‰
    """
    if not json_str or not json_str.strip():
        return {
            "is_valid": False,
            "error": "ç©ºã®JSONæ–‡å­—åˆ—ãŒæä¾›ã•ã‚Œã¾ã—ãŸ"
        }
    
    # åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
    json_str = json_str.strip()
    
    # ä¸å®Œå…¨ãªJSONã®æ¤œå‡º
    if json_str == "{" or json_str == "}":
        return {
            "is_valid": False,
            "error": f"ä¸å®Œå…¨ãªJSON: '{json_str}'"
        }
    
    if json_str.startswith("{") and not json_str.endswith("}"):
        return {
            "is_valid": False,
            "error": f"ä¸å®Œå…¨ãªJSON: é–‹ãæ‹¬å¼§ã®ã¿ '{json_str[:50]}...'"
        }
    
    if not json_str.startswith("{") and json_str.endswith("}"):
        return {
            "is_valid": False,
            "error": f"ä¸å®Œå…¨ãªJSON: é–‰ã˜æ‹¬å¼§ã®ã¿ '...{json_str[-50:]}'"
        }
    
    # æ‹¬å¼§ã®å‡è¡¡ãƒã‚§ãƒƒã‚¯
    open_braces = json_str.count('{')
    close_braces = json_str.count('}')
    if open_braces != close_braces:
        return {
            "is_valid": False,
            "error": f"æ‹¬å¼§ã®ä¸å‡è¡¡: é–‹ãæ‹¬å¼§{open_braces}å€‹ã€é–‰ã˜æ‹¬å¼§{close_braces}å€‹"
        }
    
    # è¤‡æ•°å›ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œï¼ˆæ®µéšçš„ã«ä¿®å¾©ï¼‰
    for attempt in range(3):
        try:
            result = json.loads(json_str)
            return {
                "is_valid": True,
                "data": result
            }
        except json.JSONDecodeError as e:
            logger.warning(f"validate_json_string: JSONãƒ‘ãƒ¼ã‚¹å¤±æ•— (è©¦è¡Œ{attempt + 1}): {e}")
            if attempt < 2:  # æœ€å¾Œã®è©¦è¡Œã§ãªã„å ´åˆ
                # è¿½åŠ ã®ä¿®å¾©ã‚’è©¦è¡Œ
                if "True" in json_str:
                    json_str = json_str.replace("True", "true")
                if "False" in json_str:
                    json_str = json_str.replace("False", "false")
                if "None" in json_str:
                    json_str = json_str.replace("None", "null")
                
                # ç‰¹æ®Šæ–‡å­—ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                json_str = re.sub(r'([^\\])"', r'\1\\"', json_str)
                json_str = json_str.replace('\\"', '"')  # äºŒé‡ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ä¿®æ­£
            else:
                return {
                    "is_valid": False,
                    "error": f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}"
                }
    
    return {
        "is_valid": False,
        "error": "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    }

def extract_structure_from_markdown(text: str) -> Optional[Dict[str, Any]]:
    """
    Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text (str): Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        Optional[Dict[str, Any]]: æŠ½å‡ºã•ã‚ŒãŸæ§‹æˆæƒ…å ±ã€å¤±æ•—æ™‚ã¯None
    """
    try:
        logger.debug("ğŸ” Markdownå½¢å¼ã‹ã‚‰ã®æ§‹æˆæŠ½å‡ºé–‹å§‹")
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆ# ã§å§‹ã¾ã‚‹è¡Œï¼‰
        title_match = re.search(r'^#\s*(.+)$', text, re.MULTILINE)
        title = title_match.group(1).strip() if title_match else "è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæ§‹æˆ"
        
        # èª¬æ˜ã‚’æŠ½å‡ºï¼ˆ## èª¬æ˜ ã¾ãŸã¯ èª¬æ˜: ã§å§‹ã¾ã‚‹è¡Œï¼‰
        description_match = re.search(r'(?:^##\s*èª¬æ˜\s*$|^èª¬æ˜\s*:?\s*$)(.+?)(?=^##|\Z)', text, re.MULTILINE | re.DOTALL)
        description = description_match.group(1).strip() if description_match else ""
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºï¼ˆ## ã§å§‹ã¾ã‚‹è¡Œï¼‰
        sections = {}
        section_pattern = r'^##\s*(.+?)$\s*((?:(?!^##).)*?)(?=^##|\Z)'
        section_matches = re.finditer(section_pattern, text, re.MULTILINE | re.DOTALL)
        
        for match in section_matches:
            section_name = match.group(1).strip()
            section_content = match.group(2).strip()
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã‹ã‚‰é …ç›®ã‚’æŠ½å‡º
            items = {}
            
            # ãƒªã‚¹ãƒˆé …ç›®ã‚’æŠ½å‡ºï¼ˆ- ã¾ãŸã¯ * ã§å§‹ã¾ã‚‹è¡Œï¼‰
            list_items = re.findall(r'^[-*]\s*(.+?)$', section_content, re.MULTILINE)
            if list_items:
                for i, item in enumerate(list_items):
                    items[f"item_{i+1}"] = item.strip()
            else:
                # ãƒªã‚¹ãƒˆãŒãªã„å ´åˆã¯æ®µè½ã‚’é …ç›®ã¨ã—ã¦æ‰±ã†
                paragraphs = [p.strip() for p in section_content.split('\n\n') if p.strip()]
                for i, paragraph in enumerate(paragraphs):
                    if paragraph and not paragraph.startswith('#'):
                        items[f"paragraph_{i+1}"] = paragraph
            
            if items:
                sections[section_name] = items
        
        # æ§‹æˆæƒ…å ±ã‚’æ§‹ç¯‰
        if sections:
            structure = {
                "title": title,
                "description": description,
                "content": sections
            }
            logger.debug(f"âœ… Markdownæ§‹æˆæŠ½å‡ºæˆåŠŸ: {len(sections)}å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
            return structure
        else:
            logger.warning("âš ï¸ Markdownå½¢å¼ã‹ã‚‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
            
    except Exception as e:
        logger.error(f"âŒ Markdownå½¢å¼ã‹ã‚‰ã®æ§‹æˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def repair_unquoted_keys(json_str: str) -> str:
    """
    æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’ä¿®å¾©ã™ã‚‹
    
    Args:
        json_str (str): ä¿®å¾©å¯¾è±¡ã®JSONæ–‡å­—åˆ—
        
    Returns:
        str: ä¿®å¾©ã•ã‚ŒãŸJSONæ–‡å­—åˆ—
    """
    # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®æ¤œå‡ºï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: é€šå¸¸ã®æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ (title:)
    unquoted_keys = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*:', json_str)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ—¥æœ¬èªæ–‡å­—ã‚’å«ã‚€æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ (ã€Œtitleã€:)
    japanese_unquoted_keys = re.findall(r'([ã€Œã€\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]+)\s*:', json_str)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼
    special_unquoted_keys = re.findall(r'([^\s:,\{\}\[\]"]+)\s*:', json_str)
    
    all_unquoted_keys = unquoted_keys + japanese_unquoted_keys + special_unquoted_keys
    all_unquoted_keys = list(set(all_unquoted_keys))  # é‡è¤‡ã‚’é™¤å»
    
    if all_unquoted_keys:
        logger.warning(f"æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’æ¤œå‡º: {all_unquoted_keys}")
        
        # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’ã‚¯ã‚ªãƒ¼ãƒˆã§å›²ã‚€
        for key in all_unquoted_keys:
            # æ—¢ã«ã‚¯ã‚ªãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if f'"{key}":' in json_str:
                continue
            
            # ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ã‚­ãƒ¼ã®å ´åˆã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            escaped_key = key.replace('"', '\\"').replace('\\', '\\\\')
            
            # æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’ã‚¯ã‚ªãƒ¼ãƒˆã§å›²ã‚€ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: {key: ã¾ãŸã¯ ,key:
            json_str = re.sub(rf'([{{,])\s*{re.escape(key)}\s*:', rf'\1"{escaped_key}":', json_str)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: è¡Œé ­ã®key:
            json_str = re.sub(rf'^\s*{re.escape(key)}\s*:', rf'"{escaped_key}":', json_str, flags=re.MULTILINE)
        
        logger.info(f"æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®ä¿®å¾©å®Œäº†: {len(all_unquoted_keys)}å€‹")
    
    return json_str

def extract_json_part_old(text: str) -> Optional[Dict[str, Any]]:
    """
    Geminiã®å¿œç­”ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã€æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’ä¿®å¾©
    Args:
        text: æŠ½å‡ºå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        Dict[str, Any]: æŠ½å‡ºãƒ»ä¿®å¾©ã•ã‚ŒãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    try:
        json_match = re.search(r'\{[\s\S]*\}', text)
        if not json_match:
            logger.error("No JSON object found in text")
            return None
        json_str = json_match.group(0)
        unquoted_keys = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\:', json_str)
        if unquoted_keys:
            logger.warning(f"Found unquoted keys: {unquoted_keys}")
            dump_dir = "logs"
            if not os.path.exists(dump_dir):
                os.makedirs(dump_dir)
            timestamp = datetime.now().strftime("%Y%m%d")
            dump_file = os.path.join(dump_dir, f"gemini_error_dump_{timestamp}.json")
            with open(dump_file, "a", encoding="utf-8") as f:
                f.write(f"\n=== Error at {datetime.now()} ===\n")
                f.write(f"Original text: {text}\n")
                f.write(f"Extracted JSON: {json_str}\n")
                f.write(f"Unquoted keys: {unquoted_keys}\n")
            for key in unquoted_keys:
                json_str = json_str.replace(f"{key}:", f'"{key}":')
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error in extract_json_part: {str(e)}")
        return None 