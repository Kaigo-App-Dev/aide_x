"""
AIDE-X: ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ»JSONæŠ½å‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""
import json
import logging
import os
from datetime import datetime
from typing import Dict, Any, Optional
import re

logger = logging.getLogger(__name__)

def extract_json_part(text: str) -> Dict[str, Any]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    Args:
        text (str): JSONã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        Dict[str, Any]: æŠ½å‡ºã•ã‚ŒãŸJSONãƒ‡ãƒ¼ã‚¿ï¼ˆå¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã‚€è¾æ›¸ï¼‰
    """
    if not text or not text.strip():
        logger.warning("extract_json_part: ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¾ã—ãŸ")
        return {
            "error": "JSONæ§‹æˆãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ",
            "reason": "ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¾ã—ãŸ",
            "original_text": ""
        }
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ï¼ˆGeminiå‡ºåŠ›å¯¾ç­–ï¼‰
    text = text.strip()
    
    # åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–ï¼ˆè¤‡æ•°ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’å˜ä¸€ã‚¹ãƒšãƒ¼ã‚¹ã«ï¼‰
    text = re.sub(r'\s+', ' ', text)
    
    # æ”¹è¡Œã®æ­£è¦åŒ–ï¼ˆæ”¹è¡Œã‚’é©åˆ‡ã«å‡¦ç†ï¼‰
    text = re.sub(r'\n\s*\n', '\n', text)  # é€£ç¶šæ”¹è¡Œã‚’å˜ä¸€æ”¹è¡Œã«
    text = re.sub(r'\n\s*([{}])', r'\1', text)  # æ³¢æ‹¬å¼§å‰å¾Œã®æ”¹è¡Œã‚’å‰Šé™¤
    
    logger.debug(f"extract_json_part: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆé•· = {len(text)}")
    logger.debug(f"extract_json_part: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ = {text[:500]}...")
    
    # åŸæ–‡å…¨æ–‡ã‚’logs/ã«ä¿å­˜ï¼ˆGeminiå‡ºåŠ›åˆ†æç”¨ï¼‰
    try:
        os.makedirs("logs", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = f"logs/gemini_raw_output_{timestamp}.txt"
        with open(log_file, "w", encoding="utf-8") as f:
            f.write(f"=== Gemini Raw Output at {datetime.now().isoformat()} ===\n")
            f.write(f"Text Length: {len(text)}\n")
            f.write(f"Text Content:\n{text}\n")
            f.write("=" * 50 + "\n")
        logger.info(f"ğŸ“ GeminiåŸæ–‡ã‚’ä¿å­˜: {log_file}")
    except Exception as e:
        logger.warning(f"âš ï¸ GeminiåŸæ–‡ä¿å­˜ã«å¤±æ•—: {e}")
    
    # 1. ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã‚’å„ªå…ˆçš„ã«æ¤œç´¢
    code_block_pattern = r'```(?:json)?\s*(\{[\s\S]*?\})\s*```'
    code_match = re.search(code_block_pattern, text)
    if code_match:
        json_str = code_match.group(1).strip()
        logger.debug(f"extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONã‚’æŠ½å‡º")
        try:
            result = json.loads(json_str)
            logger.debug(f"extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯JSONæŠ½å‡ºæˆåŠŸ")
            return result
        except json.JSONDecodeError as e:
            logger.warning(f"ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒå¤±æ•—ã—ãŸå ´åˆã€é€šå¸¸ã®æŠ½å‡ºã‚’è©¦è¡Œ
    
    # 2. é€šå¸¸ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œç´¢
    json_pattern = r'\{[\s\S]*?\}'
    matches = list(re.finditer(json_pattern, text))
    
    if matches:
        # è¤‡æ•°ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€æœ€ã‚‚é•·ã„ã‚‚ã®ã‚’é¸æŠ
        longest_match = max(matches, key=lambda m: len(m.group(0)))
        json_str = longest_match.group(0)
        logger.debug(f"extract_json_part: æŠ½å‡ºã•ã‚ŒãŸJSONæ–‡å­—åˆ—é•· = {len(json_str)}")
        
        # 3. æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã®ä¿®å¾©
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: {key: value} -> {"key": value}
        json_str = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_str)
        
        # 4. æœ«å°¾ã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        
        # 5. è¤‡æ•°å›ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œï¼ˆæ®µéšçš„ã«ä¿®å¾©ï¼‰
        for attempt in range(3):
            try:
                result = json.loads(json_str)
                logger.debug(f"extract_json_part: JSONæŠ½å‡ºæˆåŠŸ (è©¦è¡Œ{attempt + 1})")
                return result
            except json.JSONDecodeError as e:
                logger.warning(f"extract_json_part: JSONãƒ‘ãƒ¼ã‚¹å¤±æ•— (è©¦è¡Œ{attempt + 1}): {e}")
                if attempt < 2:  # æœ€å¾Œã®è©¦è¡Œã§ãªã„å ´åˆ
                    # è¿½åŠ ã®ä¿®å¾©ã‚’è©¦è¡Œ
                    if "True" in json_str:
                        json_str = json_str.replace("True", "true")
                    if "False" in json_str:
                        json_str = json_str.replace("False", "false")
                    if "None" in json_str:
                        json_str = json_str.replace("None", "null")
                    
                    # ç‰¹æ®Šæ–‡å­—ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                    json_str = re.sub(r'([^\\])"', r'\1\\"', json_str)
                    json_str = json_str.replace('\\"', '"')  # äºŒé‡ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ä¿®æ­£
                else:
                    logger.error(f"extract_json_part: æœ€çµ‚JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
                    logger.error(f"extract_json_part: å‡¦ç†å¾Œã®JSONæ–‡å­—åˆ— = {json_str}")
                    
                    # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã‚‚ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
                    return {
                        "error": "JSONæ§‹æˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ",
                        "reason": f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}",
                        "extracted_json_string": json_str,
                        "original_text": text[:200] + "..." if len(text) > 200 else text
                    }
    
    # 6. JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡º
    logger.info("ğŸ” JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºã‚’è©¦è¡Œ")
    extracted_structure = extract_structure_from_markdown(text)
    if extracted_structure:
        logger.info("âœ… Markdownå½¢å¼ã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºæˆåŠŸ")
        return extracted_structure
    
    # 7. æœ€çµ‚çš„ã«ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¿”ã™
    logger.error(f"extract_json_part: JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    logger.error(f"extract_json_part: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå…¨æ–‡ = {text}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆé•· = {len(text)}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®100æ–‡å­— = {text[:100]}")
    logger.error(f"extract_json_part: ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¾Œã®100æ–‡å­— = {text[-100:]}")
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´ã‚’åˆ†æ
    if "```" in text:
        logger.error(f"extract_json_part: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯å­˜åœ¨ã™ã‚‹ãŒã€JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„")
    if "{" in text and "}" in text:
        logger.error(f"extract_json_part: æ³¢æ‹¬å¼§ã¯å­˜åœ¨ã™ã‚‹ãŒã€æœ‰åŠ¹ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªã„")
    if "[" in text and "]" in text:
        logger.error(f"extract_json_part: è§’æ‹¬å¼§ï¼ˆé…åˆ—ï¼‰ã¯å­˜åœ¨ã™ã‚‹ãŒã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªã„")
    
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
    return {
        "error": "JSONæ§‹æˆãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ",
        "reason": "ãƒ†ã‚­ã‚¹ãƒˆã«æœ‰åŠ¹ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“",
        "original_text": text[:200] + "..." if len(text) > 200 else text,
        "text_length": len(text)
    }

def extract_structure_from_markdown(text: str) -> Optional[Dict[str, Any]]:
    """
    Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ§‹æˆæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text (str): Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        Optional[Dict[str, Any]]: æŠ½å‡ºã•ã‚ŒãŸæ§‹æˆæƒ…å ±ã€å¤±æ•—æ™‚ã¯None
    """
    try:
        logger.debug("ğŸ” Markdownå½¢å¼ã‹ã‚‰ã®æ§‹æˆæŠ½å‡ºé–‹å§‹")
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆ# ã§å§‹ã¾ã‚‹è¡Œï¼‰
        title_match = re.search(r'^#\s*(.+)$', text, re.MULTILINE)
        title = title_match.group(1).strip() if title_match else "è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæ§‹æˆ"
        
        # èª¬æ˜ã‚’æŠ½å‡ºï¼ˆ## èª¬æ˜ ã¾ãŸã¯ èª¬æ˜: ã§å§‹ã¾ã‚‹è¡Œï¼‰
        description_match = re.search(r'(?:^##\s*èª¬æ˜\s*$|^èª¬æ˜\s*:?\s*$)(.+?)(?=^##|\Z)', text, re.MULTILINE | re.DOTALL)
        description = description_match.group(1).strip() if description_match else ""
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºï¼ˆ## ã§å§‹ã¾ã‚‹è¡Œï¼‰
        sections = {}
        section_pattern = r'^##\s*(.+?)$\s*((?:(?!^##).)*?)(?=^##|\Z)'
        section_matches = re.finditer(section_pattern, text, re.MULTILINE | re.DOTALL)
        
        for match in section_matches:
            section_name = match.group(1).strip()
            section_content = match.group(2).strip()
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã‹ã‚‰é …ç›®ã‚’æŠ½å‡º
            items = {}
            
            # ãƒªã‚¹ãƒˆé …ç›®ã‚’æŠ½å‡ºï¼ˆ- ã¾ãŸã¯ * ã§å§‹ã¾ã‚‹è¡Œï¼‰
            list_items = re.findall(r'^[-*]\s*(.+?)$', section_content, re.MULTILINE)
            if list_items:
                for i, item in enumerate(list_items):
                    items[f"item_{i+1}"] = item.strip()
            else:
                # ãƒªã‚¹ãƒˆãŒãªã„å ´åˆã¯æ®µè½ã‚’é …ç›®ã¨ã—ã¦æ‰±ã†
                paragraphs = [p.strip() for p in section_content.split('\n\n') if p.strip()]
                for i, paragraph in enumerate(paragraphs):
                    if paragraph and not paragraph.startswith('#'):
                        items[f"paragraph_{i+1}"] = paragraph
            
            if items:
                sections[section_name] = items
        
        # æ§‹æˆæƒ…å ±ã‚’æ§‹ç¯‰
        if sections:
            structure = {
                "title": title,
                "description": description,
                "content": sections
            }
            logger.debug(f"âœ… Markdownæ§‹æˆæŠ½å‡ºæˆåŠŸ: {len(sections)}å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
            return structure
        else:
            logger.warning("âš ï¸ Markdownå½¢å¼ã‹ã‚‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
            
    except Exception as e:
        logger.error(f"âŒ Markdownå½¢å¼ã‹ã‚‰ã®æ§‹æˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_json_part_old(text: str) -> Optional[Dict[str, Any]]:
    """
    Geminiã®å¿œç­”ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã€æœªã‚¯ã‚ªãƒ¼ãƒˆã‚­ãƒ¼ã‚’ä¿®å¾©
    Args:
        text: æŠ½å‡ºå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        Dict[str, Any]: æŠ½å‡ºãƒ»ä¿®å¾©ã•ã‚ŒãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    try:
        json_match = re.search(r'\{[\s\S]*\}', text)
        if not json_match:
            logger.error("No JSON object found in text")
            return None
        json_str = json_match.group(0)
        unquoted_keys = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\:', json_str)
        if unquoted_keys:
            logger.warning(f"Found unquoted keys: {unquoted_keys}")
            dump_dir = "logs"
            if not os.path.exists(dump_dir):
                os.makedirs(dump_dir)
            timestamp = datetime.now().strftime("%Y%m%d")
            dump_file = os.path.join(dump_dir, f"gemini_error_dump_{timestamp}.json")
            with open(dump_file, "a", encoding="utf-8") as f:
                f.write(f"\n=== Error at {datetime.now()} ===\n")
                f.write(f"Original text: {text}\n")
                f.write(f"Extracted JSON: {json_str}\n")
                f.write(f"Unquoted keys: {unquoted_keys}\n")
            for key in unquoted_keys:
                json_str = json_str.replace(f"{key}:", f'"{key}":')
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error in extract_json_part: {str(e)}")
        return None 